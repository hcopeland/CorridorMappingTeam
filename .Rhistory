source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
#step 1. Create sequences from the output of Migration Mapper (tab 6)
create.seqs(shpfl_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6",  #this is the folder where files from tab 6 are located
shpfl_name= "pointsOut_20190208080234" ,  #name of the actual shapefile without the .shp
migtbl_name="migtime_20190208080234.csv",   #name of the actual csv file
out_fldr="C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/sequences",   #it will make this folder for you
out_proj="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")   #name a projection you want the output to be in. Then carry this proj through the rest of the steps
#step 2. Conduct BB analyses. You will want use parrallel processing for this one.
# This also spits out a metadata file of the results of the BB analysis
create.BBs(seqs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/sequences",    #this is the folder where all the sequences are saved
BBs_out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/UDs",  #it will make this folder for you
footprint_out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints",  #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6",
cores=11, location.error=20, cell.size=1000, max.lag=8, contour=99,
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
#Step 3. Calculate average BBs for each individual and and a population UD and population footprint.
create.BB.avgs(BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/UDs",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/UDs_pop",  #it will make this folder for you
pop_footprint_out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop",  #it will make this folder for you
contour=99,
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
# Step 4. Calculate the stopover files and the low, medium, high use corridors as shapefiles
create.corridors.stopovers(PopUD_asc = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/UDs_pop/averageUD.asc",
PopFootprint_asc = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop/popFootprint.asc",
pop_BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop",
out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/final_products",
stopover_percent=10, corridor_percents=c(10, 20), min_area = 20000,
simplify = TRUE, tolerance = 100, # how to polygons are simplified (unites are meters)
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
# Step 4. Calculate the stopover files and the low, medium, high use corridors as shapefiles
create.corridors.stopovers(PopUD_asc = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/UDs_pop/averageUD.asc",
PopFootprint_asc = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop/popFootprint.asc",
pop_BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop",
out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/final_products",
stopover_percent=10, corridor_percents=c(10, 20), min_area = 20000,
simplify = TRUE, tolerance = 100, # how to polygons are simplified (unites are meters)
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
# Step 4. Calculate the stopover files and the low, medium, high use corridors as shapefiles
create.corridors.stopovers(PopUD_asc = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/UDs_pop/averageUD.asc",
PopFootprint_asc = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop/popFootprint.asc",
pop_BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/Footprints_pop",
out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/Elk_BenchCorral_Tab6/final_products",
stopover_percent=10, corridor_percents=c(10, 20), min_area = 20000,
simplify = TRUE, tolerance = 100, # how to polygons are simplified (unites are meters)
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
mig.metadata.file="C:/Users/jmerkle/Desktop/Mapp2/tab6output/metadata.csv",
qtl.end.fall.mig=0.95, qtl.start.spring.mig=0.05
mig.metadata.file="C:/Users/jmerkle/Desktop/Mapp2/tab6output/metadata.csv"
qtl.end.fall.mig=0.95
qtl.start.spring.mig=0.05
fl <- read.csv(mig.metadata.file)
head(fl)
#manage packages
if(all("stringr" %in% installed.packages()[,1])==FALSE)
stop("You must install the following packages: stringr")
require(stringr)
fl <- read.csv(mig.metadata.file)
fl$seas <- substr(str_split_fixed(fl$input.file, "_",2)[,2],1,2)
head(fl)
table(fl$seas)
fl$Start.Date <- as.POSIXct(strptime(fl$Start.Date,format = "%Y-%m-%d %H:%M:%S"), tz="GMT")
Start.Date
fl$End.Date <- as.POSIXct(strptime(fl$End.Date,format = "%Y-%m-%d %H:%M:%S"), tz="GMT")
sp <- fl[fl$seas == "sp",]
fa <- fl[fl$seas == "fa",]
sp$jul <- as.numeric(strftime(sp$Start.Date, format = "%j", tz = "GMT"))
fa$jul <- as.numeric(strftime(fa$End.Date, format = "%j", tz = "GMT"))
wint.start <- quantile(sp$jul, probs = qtl.start.spring.mig)
wint.start
wint.start <- round(quantile(sp$jul, probs = qtl.start.spring.mig),0)
wint.start
wint.start <- round(quantile(fa$jul, probs = qtl.end.fall.mig),0)
wint.end <- round(quantile(sp$jul, probs = qtl.start.spring.mig),0)
wint.start
wint.end
wint.start <- round(quantile(fa$Start.Date, probs = qtl.end.fall.mig),0)
wint.start
fl <- read.csv(mig.metadata.file)
fl$seas <- substr(str_split_fixed(fl$input.file, "_",2)[,2],1,2)
head(fl)
nchar(fl$Start.Date[1])
nchar(fl$Start.Date)
nchar(as.character(fl$Start.Date)[1])
head(paste0("2018", substr(fl$Start.Date,5,19)))
fl <- read.csv(mig.metadata.file)
fl$seas <- substr(str_split_fixed(fl$input.file, "_",2)[,2],1,2)
fl$Start.Date <- as.POSIXct(strptime(paste0("2018", substr(fl$Start.Date,5,19)),format = "%Y-%m-%d %H:%M:%S"), tz="GMT")
fl$End.Date <- as.POSIXct(strptime(paste0("2018", substr(fl$End.Date,5,19)),format = "%Y-%m-%d %H:%M:%S"), tz="GMT")
sp <- fl[fl$seas == "sp",]
fa <- fl[fl$seas == "fa",]
sp$jul <- as.numeric(strftime(sp$Start.Date, format = "%j", tz = "GMT"))
fa$jul <- as.numeric(strftime(fa$End.Date, format = "%j", tz = "GMT"))
wint.start <- round(quantile(fa$End.Date, probs = qtl.end.fall.mig),0)
wint.start
wint.end <- round(quantile(sp$Start.Date, probs = qtl.start.spring.mig),0)
wint.end
paste(strftime(wint.start, format = "%m", tz = "GMT"),strftime(wint.start, format = "%d", tz = "GMT"),sep="-")
