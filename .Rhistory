ids <- str_split_fixed(fls, "_",3)[,1]
ids_unique <- unique(ids)
print(paste("You have ", length(ids_unique), " unique individuals with successful BBs.", sep=""))
if(length(fls)==1)
stop("You only have 1 UD. There is nothing to average!")
length(ids_unique)==1
fls2 <- fls[ids == ids_unique[1]]
bb <- raster(paste(BBs_fldr, "/", fls2[1], sep=""))
for(e in 2:length(fls2)){
bb <- addLayer(bb, raster(paste(BBs_fldr, "/", fls2[e], sep="")))
}
if(nlayers(bb) != length(fls2))
stop("You have a problem. See error 1.")
bb <- mean(bb)
bb <- bb/sum(values(bb))   #verify that they add up to 1
#output averaged individual ASCII file
m <- as(bb, "SpatialGridDataFrame")
# make sure the cell size is teh same in x and y direction.
cs <- slot(slot(m, "grid"), "cellsize")
slot(slot(m, "grid"), "cellsize") <- rep(mean(cs), 2)
write.asciigrid(m, paste(pop_BBs_out_fldr,"/",ids_unique[1],"_ASCII.asc",sep=""), attr=1)
#create overall averages
fls <- dir(pop_BBs_out_fldr)
if(length(fls)==1)
stop("You only have 1 individual. There is nothing to average across IDs.")
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/tab6output/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/tab6output/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/tab6output/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Mapp2/tab6output/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Mapp2/tab6output/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.R")
# source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.CTMMs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.lns.file.R")
#Step 3. Calculate average BBs for each individual and and a population UD and population footprint.
create.BB.avgs(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_pop",  #it will make this folder for you
pop_footprint_out_fldr = "C:/Users/jmerkle/Desktop/Elk/Footprints_pop",  #it will make this folder for you
contour=99,  # contour level used to create the footprints
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")  # this is the proj4string of your data. (should be carried through from previous functions)
BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW"
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_pop"
pop_footprint_out_fldr = "C:/Users/jmerkle/Desktop/Elk/Footprints_pop"
contour=99
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
if(all(c("stringr", "raster", "BBMM") %in% installed.packages()[,1])==FALSE)
stop("You must install the following packages: raster, BBMM, and stringr")
require(stringr)
require(raster)
require(BBMM)
#check the new directories
if(dir.exists(pop_BBs_out_fldr)==FALSE){
dir.create(pop_BBs_out_fldr)
}
if(length(dir(pop_BBs_out_fldr))> 0)
stop("Your pop_BBs_out_fldr Has something in it. It should be empty!")
if(dir.exists(pop_footprint_out_fldr)==FALSE){
dir.create(pop_footprint_out_fldr)
}
if(length(dir(pop_footprint_out_fldr))> 0)
stop("Your pop_footprint_out_fldr Has something in it. It should be empty!")
print(paste0("Start time: ", Sys.time()))
BBs_fldr
fls <- dir(BBs_fldr)
fls <- list.files(BBs_fldr, ".asc$")
print(paste("You have ", length(fls), " sequences with successful BBs.", sep=""))
install.packages("maptools")
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.R")
# source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.CTMMs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.lns.file.R")
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
#step 2. Conduct BB analyses. You will want use parrallel processing for this one.
# This also spits out a metadata file of the results of the BB analysis
create.BBs.W(seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences",    #this is the folder where all the sequences are saved
BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",  #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk",
mindays=30,   #if an individual animal has less than this many days in a given sequence of winter data, it will be removed
cores=11,    #this is the number of cores/threads you want to use for parrallel processing
location.error=20,   #location error of your GPS data in meters
cell.size=250,    #this is the cell size of the raster you'd like to fit the BBs over (should be 50m)
max.lag=8,     #this is the maximum amoung of time (in hours) that you want to allow any two points to be connected to conduct BB. You will want to make this larger if using FMV with 12 hr data!!!!
time.step=5,   # represents how often (in minutes) that BB integrates between sequential points
BMvar=NULL, # if Null, will run regular BB and calculate motion variance. If a number is specified, it will invoke the Forced motion variance method
mult4buff=0.2, # proportion of space around your gps data that is used to create the grid
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#step 2. Conduct BB analyses. You will want use parrallel processing for this one.
# This also spits out a metadata file of the results of the BB analysis
create.BBs.W(seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences",    #this is the folder where all the sequences are saved
BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",  #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk",
mindays=30,   #if an individual animal has less than this many days in a given sequence of winter data, it will be removed
cores=11,    #this is the number of cores/threads you want to use for parrallel processing
location.error=20,   #location error of your GPS data in meters
cell.size=250,    #this is the cell size of the raster you'd like to fit the BBs over (should be 50m)
max.lag=8,     #this is the maximum amoung of time (in hours) that you want to allow any two points to be connected to conduct BB. You will want to make this larger if using FMV with 12 hr data!!!!
time.step=5,   # represents how often (in minutes) that BB integrates between sequential points
BMvar=NULL, # if Null, will run regular BB and calculate motion variance. If a number is specified, it will invoke the Forced motion variance method
mult4buff=0.2, # proportion of space around your gps data that is used to create the grid
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences"
BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW"
metadata_fldr="C:/Users/jmerkle/Desktop/Elk"
if(all(c("rgdal","foreign","R.utils","stringr","BBMM","snowfall","raster") %in% installed.packages()[,1])==FALSE)
stop("You must install the following packages: rgdal, foreign, BBMM, snowfall, raster, and stringr")
require(rgdal)
require(foreign)
require(stringr)
require(BBMM)
require(raster)
require(snowfall)
require(R.utils)
#make the custom brownian bridge function... FOR FMV
BrownianBridgeCustom<-function (x, y, time.lag, location.error, area.grid = NULL, cell.size = NULL,
time.step = 10, max.lag = NULL, BMvar=BMvar)
{
if (is.null(x) | is.null(y) | (length(x) != length(y))) {
stop("data is missing or unequal number of x and y coordinates")
}
if (is.null(location.error))
stop("must specify 'location.error'")
if (is.null(area.grid) & is.null(cell.size)) {
stop("'area.grid' or 'cell.size' must be specified")
}
if (!is.null(area.grid) & is.null(cell.size)) {
cell.size <- abs(area.grid[1, 1] - area.grid[2, 1])
}
if (is.null(area.grid) & !is.null(cell.size)) {
range.x <- range(x)
range.y <- range(y)
min.grid.x <- round(range.x[1] - 1 * sd(x))
max.grid.x <- round(range.x[2] + 1 * sd(x))
min.grid.y <- round(range.y[1] - 1 * sd(y))
max.grid.y <- round(range.y[2] + 1 * sd(y))
x. <- seq(min.grid.x, max.grid.x, cell.size)
y. <- seq(min.grid.y, max.grid.y, cell.size)
area.grid <- merge(x., y.)
}
if (is.null(max.lag)) {
max.lag = max(time.lag) + 1
}
if (length(location.error) == 1) {
location.error <- rep(location.error, length(x))
}
n.locs <- length(x)
# BMvar <- brownian.motion.variance(n.locs, time.lag, location.error,
#                                   x, y, max.lag)
BMvar <- rep(BMvar, times = length(x))
if (is.null(time.step))
time.step <- 10
grid.size <- nrow(area.grid)
probability <- rep(0, grid.size)
T.Total <- sum(time.lag)
bbmm <- vector("list", 4)
names(bbmm) <- c("Brownian motion variance", "x", "y", "probability")
class(bbmm) <- "bbmm"
probability <- NULL
int <- 0
for (i in 1:(n.locs - 1)) {
if (time.lag[i] <= max.lag) {
theta <- NULL
tm <- 0
while (tm <= time.lag[i]) {
alpha <- tm/time.lag[i]
mu.x <- x[i] + alpha * (x[i + 1] - x[i])
mu.y <- y[i] + alpha * (y[i + 1] - y[i])
sigma.2 <- time.lag[i] * alpha * (1 - alpha) *
BMvar[i] + ((1 - alpha)^2) * (location.error[i]^2) +
(alpha^2) * (location.error[i + 1]^2)
ZTZ <- (area.grid[, 1] - mu.x)^2 + (area.grid[,
2] - mu.y)^2
theta <- (1/(2 * pi * sigma.2)) * exp(-ZTZ/(2 *
sigma.2))
int <- int + theta
tm <- tm + time.step
}
}
}
probability <- int/T.Total
probability <- probability/sum(probability)
bbmm[[4]] <- probability
bbmm[[1]] <- BMvar[1]
bbmm[[2]] <- area.grid[, 1]
bbmm[[3]] <- area.grid[, 2]
return(bbmm)
}
#load up teh data into a single database
fls <- list.files(seqs_fldr, ".dbf$")
print(paste0("You have ", length(fls), " sequences."))
d <- do.call(rbind, lapply(1:length(fls), function(i){
db <- read.dbf(paste(seqs_fldr, fls[i],sep="/"), as.is=TRUE)
db$wint <- sub(".dbf","",fls[i])
return(db)
}))
#check and make sure the columns are correct.
if(all(c("date","x","y") %in% names(d)) == FALSE)
stop("There is an issue with the columns in your sequences. See Error 2.")
d$date <- as.POSIXct(strptime(d$date,format = "%Y-%m-%d %H:%M:%S"), tz="GMT")
if(any(is.na(d$date)))
stop("There is an issue with your date columns. See Error 2a.")
# remove any sequences that do not have > mindays
jul <- as.numeric(strftime(d$date, format = "%j", tz = "GMT"))
u <- unique(d$wint)
ids2keep <- do.call(c, lapply(1:length(u), function(i){
if(length(unique(jul[d$wint == u[i]])) >= mindays){
return(u[i])
}else{
return(NULL)
}
}))
mindays=30
# remove any sequences that do not have > mindays or simply have very few data points (i.e., less than 1 pt per day on average)
jul <- as.numeric(strftime(d$date, format = "%j", tz = "GMT"))
u <- unique(d$wint)
length(u)
i=1
unique(jul[d$wint == u[i]])
length(unique(jul[d$wint == u[i]]))
length(unique(jul[d$wint == u[i]])) <= nrow(d)
length(unique(jul[d$wint == u[i]])) >= mindays
# remove any sequences that do not have > mindays or simply have very few data points (i.e., less than 1 pt per day on average)
jul <- as.numeric(strftime(d$date, format = "%j", tz = "GMT"))
u <- unique(d$wint)
ids2keep <- do.call(c, lapply(1:length(u), function(i){
if(length(unique(jul[d$wint == u[i]])) >= mindays | length(unique(jul[d$wint == u[i]])) <= nrow(d)){
return(u[i])
}else{
return(NULL)
}
}))
print(paste0("You are removing ", length(u)-length(ids2keep), " sequences because there are less than ", mindays, " days worth of data! Or you have less than 1 point per day, on avearge."))
# remove any sequences that do not have > mindays or simply have very few data points (i.e., less than 1 pt per day on average)
jul <- as.numeric(strftime(d$date, format = "%j", tz = "GMT"))
u <- unique(d$wint)
ids2keep <- do.call(c, lapply(1:length(u), function(i){
if(length(unique(jul[d$wint == u[i]])) >= mindays | length(unique(jul[d$wint == u[i]])) > nrow(d)){
return(u[i])
}else{
return(NULL)
}
}))
print(paste0("You are removing ", length(u)-length(ids2keep), " sequences because there are less than ", mindays, " days worth of data! Or you have less than 1 point per day, on avearge."))
# remove any sequences that do not have > mindays or simply have very few data points (i.e., less than 1 pt per day on average)
jul <- as.numeric(strftime(d$date, format = "%j", tz = "GMT"))
u <- unique(d$wint)
ids2keep <- do.call(c, lapply(1:length(u), function(i){
if(length(unique(jul[d$wint == u[i]])) >= mindays | nrow(d) > length(unique(jul[d$wint == u[i]]))){
return(u[i])
}else{
return(NULL)
}
}))
print(paste0("You are removing ", length(u)-length(ids2keep), " sequences because there are less than ", mindays, " days worth of data! Or you have less than 1 point per day, on avearge."))
i=1
length(unique(jul[d$wint == u[i]])) >= mindays
nrow(d) > length(unique(jul[d$wint == u[i]]))
# remove any sequences that do not have > mindays or simply have very few data points (i.e., less than 1 pt per day on average)
jul <- as.numeric(strftime(d$date, format = "%j", tz = "GMT"))
u <- unique(d$wint)
ids2keep <- do.call(c, lapply(1:length(u), function(i){
if(length(unique(jul[d$wint == u[i]])) >= mindays & nrow(d) > length(unique(jul[d$wint == u[i]]))){
return(u[i])
}else{
return(NULL)
}
}))
print(paste0("You are removing ", length(u)-length(ids2keep), " sequences because there are less than ", mindays, " days worth of data! Or you have less than 1 point per day, on avearge."))
d <- d[d$wint %in% ids2keep,]
nrow(d)==0
if(nrow(d) < 4)
stop("Error. You don't have any sequences left to calculate BBs.")
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.R")
# source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.CTMMs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.lns.file.R")
#step 2. Conduct BB analyses. You will want use parrallel processing for this one.
# This also spits out a metadata file of the results of the BB analysis
create.BBs(seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences",    #this is the folder where all the sequences are saved
BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs",  #it will make this folder for you
footprint_out_fldr = "C:/Users/jmerkle/Desktop/Elk/Footprints",  #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk",
cores=11,    #this is the number of cores/threads you want to use for parrallel processing
location.error=20,   #location error of your GPS data in meters
cell.size=1000,    #this is the cell size of the raster you'd like to fit the BBs over (should be 50m)
max.lag=8,     #this is the maximum amoung of time (in hours) that you want to allow any two points to be connected to conduct BB. You will want to make this larger if using FMV with 12 hr data!!!!
contour=99,    # contour level used to create the footprints
time.step=5,   # represents how often (in minutes) that BB integrates between sequential points
BMvar=NULL, # if NULL, will run regular BB and calculate motion variance. If a number is specified, it will invoke the Forced motion variance method
mult4buff=0.2, # proportion of space around your gps data that is used to create the grid
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#Step 3. Calculate average BBs for each individual and and a population UD and population footprint.
create.BB.avgs(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_pop",  #it will make this folder for you
pop_footprint_out_fldr = "C:/Users/jmerkle/Desktop/Elk/Footprints_pop",  #it will make this folder for you
contour=99,  # contour level used to create the footprints
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")  # this is the proj4string of your data. (should be carried through from previous functions)
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.R")
# source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.CTMMs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.lns.file.R")
#Step 3. Calculate average BBs for each individual and and a population UD and population footprint.
create.BB.avgs(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_pop",  #it will make this folder for you
pop_footprint_out_fldr = "C:/Users/jmerkle/Desktop/Elk/Footprints_pop",  #it will make this folder for you
contour=99,  # contour level used to create the footprints
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")  # this is the proj4string of your data. (should be carried through from previous functions)
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
#source the functions you will need
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.W.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.core.areas.W.R")
#step 2. Conduct BB analyses. You will want use parrallel processing for this one.
# This also spits out a metadata file of the results of the BB analysis
create.BBs.W(seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences",    #this is the folder where all the sequences are saved
BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",  #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk",
mindays=30,   #if an individual animal has less than this many days in a given sequence of winter data, it will be removed
cores=11,    #this is the number of cores/threads you want to use for parrallel processing
location.error=20,   #location error of your GPS data in meters
cell.size=250,    #this is the cell size of the raster you'd like to fit the BBs over (should be 50m)
max.lag=8,     #this is the maximum amoung of time (in hours) that you want to allow any two points to be connected to conduct BB. You will want to make this larger if using FMV with 12 hr data!!!!
time.step=5,   # represents how often (in minutes) that BB integrates between sequential points
BMvar=NULL, # if Null, will run regular BB and calculate motion variance. If a number is specified, it will invoke the Forced motion variance method
mult4buff=0.2, # proportion of space around your gps data that is used to create the grid
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
#Step 3. Calculate average BBs for each individual and and a population UD.
create.BB.avgs.W(BBs_fldr = "C:/Users/jmerkle/Desktop/Elk/UDsW",    #this is the folder where all the UDs are saved.
pop_BBs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs_popW",  #it will make this folder for you
proj_of_ascs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")    # this is the proj4string of your data. (should be carried through from previous functions)
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.seqs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BBs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.CTMMs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.BB.avgs.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.corridors.stopovers.R")
source("C:/Users/jmerkle/Documents/GitHub/CorridorMappingTeam/functions/create.lns.file.R")
create.CTMMs(seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences",  #this is the folder where all the sequences are saved
CTMMs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs2", #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk",
cores=11,   #this is the number of cores/threads you want to use for parrallel processing
cell.size=250,  #this is the cell size of the raster you'd like to fit the CTMMs over (should be 50m)
mult4buff=0.2, # proportion of space around your gps data that is used to create the grid
Information_Criteria="AIC", #Information criteria used for selection. Can be "AICc", "AIC", "BIC", "LOOCV" or none (NA). Use LOOCV for 12 hour data. Use something else like AIC for more frequent fixes
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
create.CTMMs(seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences",  #this is the folder where all the sequences are saved
CTMMs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs2", #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk",
cores=11,   #this is the number of cores/threads you want to use for parrallel processing
cell.size=250,  #this is the cell size of the raster you'd like to fit the CTMMs over (should be 50m)
mult4buff=0.2, # proportion of space around your gps data that is used to create the grid
Information_Criteria="AIC", #Information criteria used for selection. Can be "AICc", "AIC", "BIC", "LOOCV" or none (NA). Use LOOCV for 12 hour data. Use something else like AIC for more frequent fixes
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0")
seqs_fldr = "C:/Users/jmerkle/Desktop/Elk/sequences"  #this is the folder where all the sequences are saved
CTMMs_out_fldr = "C:/Users/jmerkle/Desktop/Elk/UDs2" #it will make this folder for you
metadata_fldr="C:/Users/jmerkle/Desktop/Elk"
cores=11   #this is the number of cores/threads you want to use for parrallel processing
cell.size=250  #this is the cell size of the raster you'd like to fit the CTMMs over (should be 50m)
mult4buff=0.2 # proportion of space around your gps data that is used to create the grid
Information_Criteria="AIC" #Information criteria used for selection. Can be "AICc", "AIC", "BIC", "LOOCV" or none (NA). Use LOOCV for 12 hour data. Use something else like AIC for more frequent fixes
proj_of_dbfs="+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
if(all(c("rgdal","fields","foreign","snowfall","raster","data.table","ctmm") %in% installed.packages()[,1])==FALSE)
stop("You must install the following packages: rgdal, fields, foreign, snowfall, raster, data.table, and ctmm")
require(snowfall)
require(raster)
require(data.table)
require(rgdal)
require(ctmm)
require(fields)
require(foreign)
#check the new directories
if(dir.exists(CTMMs_out_fldr)==FALSE){
dir.create(CTMMs_out_fldr)
}
if(length(dir(CTMMs_out_fldr))> 0)
stop("Your CTMMs_out_fldr Has something in it. It should be empty!")
if(dir.exists(metadata_fldr)==FALSE){
dir.create(metadata_fldr)
}
print(paste0("Start time: ", Sys.time()))
#load up teh data into a single database
fls <- dir(seqs_fldr)
print(paste0("You have ", length(fls), " sequences."))
d <- do.call(rbind, lapply(1:length(fls), function(i){
db <- read.dbf(paste(seqs_fldr, fls[i],sep="/"), as.is=TRUE)
db$mig <- sub(".dbf","",fls[i])
return(db)
}))
#check and make sure the columns are correct.
if(all(c("date","x","y") %in% names(d)) == FALSE)
stop("There is an issue with the columns in your sequences. See Error 2.")
# create migration distances
u <- unique(d$mig)
mig_dists <- do.call(rbind, lapply(1:length(u), function(i){
return(data.frame(mig=u[i], max_dist=max(rdist(d[d$mig==u[i],c("x","y")]))/1000))
}))
head(mig_dists)
hist(mig_dists$max_dist)
mig_dists$mean_max_dist <- mean(mig_dists$max_dist)
mig_dists$sd_max_dist <- sd(mig_dists$max_dist)
mig_dists$min_max_dist <- min(mig_dists$max_dist)
mig_dists$max_max_dist <- max(mig_dists$max_dist)
mig_dists
#prepare the data for ctmm analysis
d$date <- as.POSIXct(strptime(d$date,format = "%Y-%m-%d %H:%M:%S"), tz="GMT")
coordinates(d) <- c("x","y")
proj4string(d) <- proj_of_dbfs
spr_tr <- spTransform(d, CRS("+proj=longlat"))
spr_tr$longitude <-  coordinates(spr_tr)[,1]
spr_tr$latitude <-  coordinates(spr_tr)[,2]
proj_new <- CRS(proj4string(spr_tr))
d <- as.data.frame(spr_tr)
# set extent
dsp <- d # used data from all individs. here to prevent extent problems in pop-level averaging
coordinates(dsp) <- c("longitude", "latitude")
proj4string(dsp) <- CRS("+proj=longlat")
dsp_proj <- spTransform(dsp, crs(proj_of_dbfs))
dsp_proj$x <-  coordinates(dsp_proj)[,1]
dsp_proj$y <-  coordinates(dsp_proj)[,2]
ext <- extent(dsp_proj)
multiplyers <- c((ext[2]-ext[1])*mult4buff, (ext[4]-ext[3])*mult4buff)
ext <- raster::extend(ext, multiplyers)   #this will be used inside the loop to extend each UD so it can be summed up
u <- unique(d$mig)
u
i=1
df <- d[d$mig == u[i],]
nrow(df) <5
df <- df[order(df$date), ]
telem <- as.telemetry(df, projection = CRS(proj_of_dbfs))
# store guesstimated parameters of models (not including BM)
GUESS <- ctmm.guess(telem, interactive = FALSE)
# run model selection
FITS <- ctmm.select(telem, CTMM = GUESS, IC = Information_Criteria,
verbose = TRUE, method = "pHREML")
# extract top 3 model fits
mod1 <- FITS[[1]]
mod2 <- FITS[[2]]
mod3 <- FITS[[3]]
LOOCV = c(mod1$LOOCV, mod2$LOOCV, mod3$LOOCV)
#AICc = c(mod1$AICc, mod2$AICc, mod3$AICc)
temp1 <- setDT(data.frame(summary(FITS[1:3], IC = "LOOCV", MSPE = "velocity")),
keep.rownames = "model")
str(mod1)
mod1[,Information_Criteria]
mod1[[Information_Criteria]]
info = c(mod1[[Information_Criteria]], mod2[[Information_Criteria]], mod3[[Information_Criteria]])
#AICc = c(mod1$AICc, mod2$AICc, mod3$AICc)
temp1 <- setDT(data.frame(summary(FITS[1:3], IC = Information_Criteria, MSPE = "velocity")),
keep.rownames = "model")
temp1
colnames(temp1) <- c("model", paste0("delta",Information_Criteria) "deltaMSPE", "DOF")
colnames(temp1) <- c("model", paste0("delta",Information_Criteria), "deltaMSPE", "DOF")
temp2 <- data.frame(Animal_ID = rep(u[i], nrow(temp1)))
temp3 <- cbind(temp2, temp1)
temp3
temp3
